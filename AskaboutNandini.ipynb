{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwpIei9C851thkdhrUOKBw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandinisitlani2/LLM/blob/main/AskaboutNandini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAcsiCMJbVbi",
        "outputId": "f2d59fe7-70e7-4a4e-dcfe-4d591c815f08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "load_dotenv(find_dotenv(), override=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pypdf -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a67XHKE2bqfj",
        "outputId": "72aba484-8148-4d2b-cb3b-ceb21e69e326"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/256.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/256.1 kB\u001b[0m \u001b[31m934.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m256.0/256.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/256.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv -q"
      ],
      "metadata": {
        "id": "j8h3kovqcR8-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW1r9_l9eHUp",
        "outputId": "167507bc-3cd6-41a5-8639-aae9b86619e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.245-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.13-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.11 (from langchain)\n",
            "  Downloading langsmith-0.0.15-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.13 langchain-0.0.245 langsmith-0.0.15 marshmallow-3.20.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_document(file):\n",
        "  from langchain.document_loaders import PyPDFLoader\n",
        "  print(f\"loading{file}\")\n",
        "  loader=PyPDFLoader(file)\n",
        "  data=loader.load()\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "xIboStr4cl-H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data =load_document(\"/content/nandinillmtrainingdoc.pdf\")\n",
        "print(data[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugyTZ6xddVf7",
        "outputId": "4250f2d4-1621-4875-d67f-3fdf82771b81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading/content/nandinillmtrainingdoc.pdf\n",
            "aimed\n",
            "to\n",
            "effectively\n",
            "classify\n",
            "abstracts\n",
            "into\n",
            "summary,\n",
            "conclusion,\n",
            "objective,\n",
            "and\n",
            "other\n",
            "categories.\n",
            "Through\n",
            "rigorous\n",
            "model\n",
            "training\n",
            "and\n",
            "optimization,\n",
            "including\n",
            "hyperparameter\n",
            "tuning\n",
            "and\n",
            "cross-validation,\n",
            "I\n",
            "ensured\n",
            "the\n",
            "system's\n",
            "superior\n",
            "performance\n",
            "and\n",
            "generalization\n",
            "on\n",
            "unseen\n",
            "data.\n",
            "My\n",
            "work\n",
            "also\n",
            "entailed\n",
            "evaluating\n",
            "the\n",
            "model's\n",
            "effectiveness\n",
            "using\n",
            "crucial\n",
            "metrics\n",
            "like\n",
            "accuracy,\n",
            "precision,\n",
            "recall,\n",
            "and\n",
            "F1-score,\n",
            "allowing\n",
            "me\n",
            "to\n",
            "benchmark\n",
            "the\n",
            "results\n",
            "against\n",
            "baseline\n",
            "models\n",
            "and\n",
            "state-of-the-art\n",
            "techniques.\n",
            "As\n",
            "a\n",
            "result\n",
            "of\n",
            "these\n",
            "endeavors,\n",
            "I\n",
            "successfully\n",
            "developed\n",
            "an\n",
            "AI-based\n",
            "system\n",
            "achieving\n",
            "an\n",
            "impressive\n",
            "92%\n",
            "accuracy\n",
            "and\n",
            "80%\n",
            "precision\n",
            "in\n",
            "object\n",
            "detection\n",
            "from\n",
            "images,\n",
            "significantly\n",
            "outperforming\n",
            "previous\n",
            "methods.\n",
            "Secretary\n",
            "Microsoft\n",
            "Tech\n",
            "Club\n",
            "During\n",
            "my\n",
            "tenure\n",
            "as\n",
            "Secretary\n",
            "at\n",
            "Microsoft\n",
            "Tech\n",
            "Club,\n",
            "I\n",
            "not\n",
            "only\n",
            "fulfilled\n",
            "administrative\n",
            "responsibilities\n",
            "but\n",
            "also\n",
            "actively\n",
            "engaged\n",
            "in\n",
            "various\n",
            "creative\n",
            "and\n",
            "organizational\n",
            "endeavors.\n",
            "Beyond\n",
            "my\n",
            "role\n",
            "in\n",
            "managing\n",
            "club\n",
            "affairs,\n",
            "I\n",
            "enthusiastically\n",
            "undertook\n",
            "graphic\n",
            "designing\n",
            "activities,\n",
            "utilizing\n",
            "my\n",
            "artistic\n",
            "skills\n",
            "to\n",
            "craft\n",
            "visually\n",
            "captivating\n",
            "content\n",
            "for\n",
            "the\n",
            "club's\n",
            "promotional\n",
            "materials\n",
            "and\n",
            "events.\n",
            "Additionally,\n",
            "I\n",
            "played\n",
            "a\n",
            "pivotal\n",
            "role\n",
            "in\n",
            "organizing\n",
            "and\n",
            "coordinating\n",
            "a\n",
            "series\n",
            "of\n",
            "successful\n",
            "workshops\n",
            "and\n",
            "events\n",
            "tailored\n",
            "to\n",
            "the\n",
            "needs\n",
            "of\n",
            "students.\n",
            "These\n",
            "initiatives\n",
            "aimed\n",
            "to\n",
            "foster\n",
            "a\n",
            "vibrant\n",
            "learning\n",
            "environment,\n",
            "where\n",
            "members\n",
            "could\n",
            "explore\n",
            "the\n",
            "latest\n",
            "advancements\n",
            "in\n",
            "technology\n",
            "and\n",
            "acquire\n",
            "valuable\n",
            "industry\n",
            "insights.\n",
            "Through\n",
            "my\n",
            "dedication\n",
            "and\n",
            "passion\n",
            "for\n",
            "technology\n",
            "and\n",
            "design,\n",
            "I\n",
            "contributed\n",
            "to\n",
            "the\n",
            "club's\n",
            "growth\n",
            "and\n",
            "success,\n",
            "leaving\n",
            "a\n",
            "positive\n",
            "impact\n",
            "on\n",
            "the\n",
            "academic\n",
            "community.\n",
            "Web\n",
            "Developer\n",
            "Internship\n",
            "Groupe\n",
            "Veritas\n",
            "June\n",
            "2021\n",
            "-\n",
            "September\n",
            "2021,\n",
            "Mumbai,\n",
            "Maharashtra,\n",
            "India\n",
            "As\n",
            "a\n",
            "software\n",
            "developer\n",
            "intern\n",
            "at\n",
            "Veritas,\n",
            "I\n",
            "had\n",
            "the\n",
            "privilege\n",
            "of\n",
            "leading\n",
            "the\n",
            "development\n",
            "of\n",
            "a\n",
            "multi-level\n",
            "web\n",
            "application\n",
            "featuring\n",
            "user\n",
            "rights-based\n",
            "authorization\n",
            "for\n",
            "enhanced\n",
            "data\n",
            "security.\n",
            "To\n",
            "ensure\n",
            "robust\n",
            "user\n",
            "authentication,\n",
            "I\n",
            "implemented\n",
            "a\n",
            "login\n",
            "page\n",
            "using\n",
            "JavaScript\n",
            "and\n",
            "jQuery,\n",
            "providing\n",
            "a\n",
            "seamless\n",
            "and\n",
            "secure\n",
            "user\n",
            "experience.\n",
            "To\n",
            "store\n",
            "user-entered\n",
            "data,\n",
            "I\n",
            "utilised\n",
            "MySQL\n",
            "with\n",
            "strong\n",
            "security\n",
            "measures,\n",
            "safeguarding\n",
            "sensitive\n",
            "information.\n",
            "To\n",
            "enhance\n",
            "data\n",
            "entry\n",
            "efficiency,\n",
            "I\n",
            "introduced\n",
            "autofill\n",
            "functionality,\n",
            "which\n",
            "extracted\n",
            "information\n",
            "from\n",
            "existing\n",
            "records,\n",
            "streamlining\n",
            "the\n",
            "process\n",
            "for\n",
            "users.\n",
            "The\n",
            "application's\n",
            "user\n",
            "interface\n",
            "was\n",
            "thoughtfully\n",
            "designed\n",
            "using\n",
            "CSS\n",
            "and\n",
            "Bootstrap,\n",
            "ensuring\n",
            "an\n",
            "intuitive\n",
            "and\n",
            "visually\n",
            "appealing\n",
            "experience.\n",
            "Additionally,\n",
            "I\n",
            "focused\n",
            "on\n",
            "improving\n",
            "data\n",
            "management\n",
            "by\n",
            "creating\n",
            "an\n",
            "easy-to-use\n",
            "edit\n",
            "page,\n",
            "empowering\n",
            "users\n",
            "to\n",
            "modify\n",
            "existing\n",
            "records\n",
            "effortlessly.\n",
            "Overall,\n",
            "my\n",
            "contributions\n",
            "significantly\n",
            "enhanced\n",
            "the\n",
            "application's\n",
            "functionality,\n",
            "security,\n",
            "and\n",
            "usability,\n",
            "thereby\n",
            "positively\n",
            "impacting\n",
            "the\n",
            "user\n",
            "experience.\n",
            "PROJECTS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_data(data,chunk_size=256):\n",
        "  from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "  text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=0)\n",
        "  chunks=text_splitter.split_documents(data)\n",
        "\n",
        "  return chunks\n"
      ],
      "metadata": {
        "id": "poMqlmgSdwoQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks=chunk_data(data)"
      ],
      "metadata": {
        "id": "0vzra2WAdtFR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LoZoQj_d39m",
        "outputId": "ccee440f-bf07-4f5e-f881-7b1d09a9e1a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAZJ7wwSeFI2",
        "outputId": "7947aa44-111a-4aa4-e6ce-e2f27adfea1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/1.7 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_embedding_cost(texts):\n",
        "    import tiktoken\n",
        "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
        "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
        "    print(f'Total Tokens: {total_tokens}')\n",
        "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}')"
      ],
      "metadata": {
        "id": "uNyy3s4id55p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_embedding_cost(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpFCGjQZePAB",
        "outputId": "340461d7-2761-44f4-cdea-8ea7c8d01ca0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tokens: 10893\n",
            "Embedding Cost in USD: 0.004357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone-client -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Un8m15esFJ",
        "outputId": "5c0b6478-19b6-427b-b950-818ee8d44644"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/179.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_or_fetch_embeddings(index_name):\n",
        "    import pinecone\n",
        "    from langchain.vectorstores import Pinecone\n",
        "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=\"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\")\n",
        "\n",
        "    pinecone.init(api_key='f2bc4aa6-d66e-4638-a6e2-85202918805b', environment='us-west1-gcp-free',\n",
        "                  openai_api_key=\"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\")\n",
        "\n",
        "    if index_name in pinecone.list_indexes():\n",
        "        print(f'Index {index_name} already exists. Loading embeddings ... ', end='')\n",
        "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
        "        print('Ok')\n",
        "    else:\n",
        "        print(f'Creating index {index_name} and embeddings ...', end='')\n",
        "        pinecone.create_index(index_name, dimension=1536, metric='cosine')\n",
        "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
        "        print('Ok')\n",
        "\n",
        "    return vector_store"
      ],
      "metadata": {
        "id": "oGHYdn0SeSk5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_pinecone_index(index_name='all'):\n",
        "    import pinecone\n",
        "    pinecone.init(openai_api_key=\"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\",\n",
        "                              api_key=\"f2bc4aa6-d66e-4638-a6e2-85202918805b\",\n",
        "                              environment=\"us-west1-gcp-free\")\n",
        "\n",
        "    if index_name == 'all':\n",
        "        indexes = pinecone.list_indexes()\n",
        "        print('Deleting all indexes ... ')\n",
        "        for index in indexes:\n",
        "            pinecone.delete_index(index)\n",
        "\n",
        "    else:\n",
        "        print(f'Deleting index {index_name} ...', end='')\n",
        "        pinecone.delete_index(index_name)\n",
        ""
      ],
      "metadata": {
        "id": "3c2BihzxgF5B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_pinecone_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_GRejo-gPeL",
        "outputId": "06f0789b-6a15-427f-eaa7-54a53df8865d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting all indexes ... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name=\"askaboutme\"\n",
        "vector_store=insert_or_fetch_embeddings(index_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T0Yh-TXgiut",
        "outputId": "b22220fa-b222-4216-c598-4a45b990043e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating index askaboutme and embeddings ..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-BcZbzL1YPltlPxIpV59oG0pC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-BcZbzL1YPltlPxIpV59oG0pC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-BcZbzL1YPltlPxIpV59oG0pC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-BcZbzL1YPltlPxIpV59oG0pC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-BcZbzL1YPltlPxIpV59oG0pC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-BcZbzL1YPltlPxIpV59oG0pC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-BcZbzL1YPltlPxIpV59oG0pC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-BcZbzL1YPltlPxIpV59oG0pC on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai --q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYc7U1xlh9g4",
        "outputId": "0c95f0f9-ebbb-435b-af67-659cfc599a12"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/73.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using an llm to get answers in human language"
      ],
      "metadata": {
        "id": "hT-I8I0mh_UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_and_get_answer(vector_store, q):\n",
        "    from langchain.chains import RetrievalQA\n",
        "    from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1,openai_api_key=\"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\")\n",
        "\n",
        "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
        "\n",
        "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "    answer = chain.run(q)\n",
        "    return answer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1ZxG1j9jYgd"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"what are her top skills\"\n",
        "\n",
        "answer=ask_and_get_answer(vector_store,q)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y47PuCZcjuOE",
        "outputId": "762898e1-be23-43cf-c75a-fc907083282f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the given context, her top skills are:\n",
            "\n",
            "1. Machine Learning: She gained proficiency in applying machine learning to real-world problems, specifically in the domain of real estate pricing. This indicates her ability to develop and implement machine learning algorithms.\n",
            "\n",
            "2. Data Science: Her experience and expertise in machine learning demonstrate her strong skills in data science. This includes data analysis, data manipulation, and utilizing statistical techniques to extract insights from data.\n",
            "\n",
            "3. Model Deployment: Her knowledge and experience in model deployment suggest that she can take machine learning models and deploy them in real-world applications. This involves integrating models into systems so that they can be utilized by end-users.\n",
            "\n",
            "4. Decision-Making: The mentioned project has honed her ability to make informed decisions regarding model selection and optimization. This indicates her strong critical thinking and problem-solving skills in the field of data science and machine learning.\n",
            "\n",
            "Note: These skills are inferred from the given context and may not encompass all of her skills.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "i = 1\n",
        "print('Write Quit or Exit to quit.')\n",
        "while True:\n",
        "    q = input(f'Question #{i}: ')\n",
        "    i = i + 1\n",
        "    if q.lower() in ['quit', 'exit']:\n",
        "        print('Quitting ... !')\n",
        "        time.sleep(2)\n",
        "        break\n",
        "\n",
        "    answer = ask_and_get_answer(vector_store, q)\n",
        "    print(f'\\nAnswer: {answer}')\n",
        "    print(f'\\n {\"-\" * 50} \\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "zAbgSChGj7f7",
        "outputId": "cc2ebf34-266f-4535-ff6f-845ade765924"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write Quit or Exit to quit.\n",
            "Question #1: tell me the summary about nandini's skills and experiences\n",
            "\n",
            "Answer: Nandini Sitlani is a recent graduate in Computer Science with a strong passion for Machine Learning and Data Science. She possesses the ability to address complex data challenges effectively. Nandini has a strong foundation in Tableau, enabling her to create visually appealing and data-driven dashboards. She also has experience in creating insightful data visualizations using libraries like Matplotlib and Seaborn. Additionally, Nandini exhibits competence in exploring and analyzing data for data analysis purposes.\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Question #2: what are her top skills\n",
            "\n",
            "Answer: Based on the given context, her top skills could include:\n",
            "- Proficiency in applying machine learning to real-world problems\n",
            "- Experience in the domain of real estate pricing\n",
            "- Ability to make informed decisions regarding model selection and optimization\n",
            "- Development and deployment of machine learning models\n",
            "- Well-rounded knowledge in data science and machine learning\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Question #3: tell me about her work experience\n",
            "\n",
            "Answer: Her work experience includes gaining proficiency in applying machine learning to real-world problems, specifically in the domain of real estate pricing. Through projects and case studies, she developed valuable insights into the practical applications of Data Science in various industries. She also learned how to make informed decisions regarding model selection and optimization, and gained expertise in selecting the most suitable approach for each problem type.\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-ad3609442bba>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Write Quit or Exit to quit.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Question #{i}: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adding memory"
      ],
      "metadata": {
        "id": "6LaCZZJPlNAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_with_memory(vector_store, question, chat_history=[]):\n",
        "    from langchain.chains import ConversationalRetrievalChain\n",
        "    from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "    llm = ChatOpenAI(temperature=1,openai_api_key=\"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\")\n",
        "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
        "\n",
        "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
        "    result = crc({'question': question, 'chat_history': chat_history})\n",
        "    chat_history.append((question, result['answer']))\n",
        "\n",
        "    return result, chat_history"
      ],
      "metadata": {
        "id": "2FWEEuZgmUKt"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mqe3HodSmd86"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}